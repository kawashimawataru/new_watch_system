"""
Monte Carlo Strategist: MCTS-based Win Rate Predictor

ç¾åœ¨ã®ç›¤é¢ã‹ã‚‰è¤‡æ•°å›ã®ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³(rollouts)ã‚’å®Ÿè¡Œã—ã€
æœ€ã‚‚å‹ç‡ã®é«˜ã„è¡Œå‹•ã‚’ç‰¹å®šã™ã‚‹ã€‚ãƒ‡ãƒ¼ã‚¿0ä»¶ã§å‹•ä½œå¯èƒ½ã€‚

ä½¿ç”¨æ–¹æ³•:
    from predictor.player.monte_carlo_strategist import MonteCarloStrategist
    
    strategist = MonteCarloStrategist(n_rollouts=1000)
    
    result = strategist.predict_win_rate(battle_state)
    # => {
    #     "player_a_win_rate": 0.53,
    #     "player_b_win_rate": 0.47,
    #     "optimal_action": {"type": "move", "move": "Make It Rain", "target": 1},
    #     "optimal_action_win_rate": 0.53,
    #     "action_win_rates": {...}
    # }

å®Ÿè£…ãƒ•ã‚§ãƒ¼ã‚º: P1-3-B (Week 1)
å„ªå…ˆåº¦: CRITICAL ğŸ”¥
"""

from __future__ import annotations

import copy
import random
from dataclasses import dataclass
from typing import Any, Dict, List, Optional, Tuple

from predictor.core.models import (
    BattleState,
    PlayerState,
    PokemonBattleState,
    ActionCandidate
)
from predictor.core.eval_algorithms.heuristic_eval import HeuristicEvaluator
from predictor.engine.smogon_calc_wrapper import SmogonCalcWrapper


@dataclass
class Action:
    """
    ãƒãƒˆãƒ«ä¸­ã®è¡Œå‹•ã‚’è¡¨ç¾
    
    VGCã¯ãƒ€ãƒ–ãƒ«ãƒãƒˆãƒ«ãªã®ã§ã€ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã¯å„ã‚¿ãƒ¼ãƒ³ã«2ä½“åˆ†ã®è¡Œå‹•ã‚’é¸æŠã™ã‚‹ã€‚
    """
    type: str  # "move", "switch", "terastallize"
    pokemon_slot: int  # 0 or 1 (ã©ã¡ã‚‰ã®ãƒã‚±ãƒ¢ãƒ³ã®è¡Œå‹•ã‹)
    move_name: Optional[str] = None  # type="move"ã®å ´åˆ
    target_slot: Optional[int] = None  # æ”»æ’ƒå¯¾è±¡ (0, 1, 2, 3)
    switch_to: Optional[str] = None  # type="switch"ã®å ´åˆ
    tera_type: Optional[str] = None  # type="terastallize"ã®å ´åˆ


@dataclass
class TurnAction:
    """1ã‚¿ãƒ¼ãƒ³ã®è¡Œå‹•ã‚»ãƒƒãƒˆ (VGCã§ã¯2ä½“åˆ†)"""
    player_a_actions: List[Action]  # [pokemon_0ã®è¡Œå‹•, pokemon_1ã®è¡Œå‹•]
    player_b_actions: List[Action]


class MonteCarloStrategist:
    """
    Monte Carlo Tree Search (MCTS) ã«ã‚ˆã‚‹å‹ç‡äºˆæ¸¬ã‚¨ãƒ³ã‚¸ãƒ³
    
    ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ :
    1. ç¾åœ¨ã®ç›¤é¢ã‹ã‚‰ã€å…¨ã¦ã®åˆæ³•æ‰‹ã‚’åˆ—æŒ™
    2. å„è¡Œå‹•ã«ã¤ã„ã¦ n_rollouts / len(actions) å›ãšã¤ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
    3. ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã”ã¨ã«ã€ãƒãƒˆãƒ«ãŒçµ‚äº†ã™ã‚‹ã¾ã§ãƒ©ãƒ³ãƒ€ãƒ ãªæ‰‹ã‚’æ‰“ã¡ç¶šã‘ã‚‹
    4. æœ€çµ‚çš„ãªå‹æ•—ã‚’è¨˜éŒ²ã—ã€æœ€ã‚‚å‹ç‡ã®é«˜ã„è¡Œå‹•ã‚’ã€Œæœ€é©æ‰‹ã€ã¨ã—ã¦è¿”ã™
    
    è©•ä¾¡é–¢æ•°:
    - æ—¢å­˜ã® PositionEvaluator (heuristic_eval) ã‚’æ´»ç”¨
    - ãƒãƒˆãƒ«çµ‚äº†åˆ¤å®šã«ä½¿ç”¨
    
    ãƒ‡ãƒ¼ã‚¿ä¾å­˜:
    - 0ä»¶ (ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ™ãƒ¼ã‚¹ã®ãŸã‚å­¦ç¿’ä¸è¦)
    """
    
    def __init__(
        self,
        n_rollouts: int = 1000,
        max_turns: int = 50,
        use_heuristic: bool = True,
        random_seed: Optional[int] = None,
        use_damage_calc: bool = False  # Phase 1: ãƒ€ãƒ¡ãƒ¼ã‚¸è¨ˆç®—ã¯ç°¡æ˜“ç‰ˆ
    ):
        """
        Args:
            n_rollouts: ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³è©¦è¡Œå›æ•° (æ¨å¥¨: 500-1000)
            max_turns: 1è©¦åˆã®æœ€å¤§ã‚¿ãƒ¼ãƒ³æ•° (ç„¡é™ãƒ«ãƒ¼ãƒ—é˜²æ­¢)
            use_heuristic: ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯è©•ä¾¡ã‚’ä½¿ç”¨ã™ã‚‹ã‹
            random_seed: å†ç¾æ€§ã®ãŸã‚ã®ä¹±æ•°ã‚·ãƒ¼ãƒ‰
            use_damage_calc: smogon_calc_wrapper ã‚’ä½¿ç”¨ã™ã‚‹ã‹ (Phase 2ä»¥é™)
        """
        self.n_rollouts = n_rollouts
        self.max_turns = max_turns
        self.use_heuristic = use_heuristic
        self.use_damage_calc = use_damage_calc
        
        if random_seed is not None:
            random.seed(random_seed)
        
        # è©•ä¾¡å™¨ã‚’åˆæœŸåŒ–
        self.evaluator = HeuristicEvaluator()
        
        # ãƒ€ãƒ¡ãƒ¼ã‚¸è¨ˆç®—å™¨ (Phase 2ä»¥é™ã§ä½¿ç”¨)
        self.damage_calc = None
        if use_damage_calc:
            try:
                self.damage_calc = SmogonCalcWrapper()
            except Exception:
                pass  # Fallback to simple damage
        
        # çµ±è¨ˆæƒ…å ±
        self.total_simulations = 0
        self.cache_hits = 0
    
    def predict_win_rate(
        self,
        battle_state: BattleState,
        verbose: bool = False
    ) -> Dict[str, Any]:
        """
        ç¾åœ¨ã®ç›¤é¢ã‹ã‚‰å‹ç‡ã‚’äºˆæ¸¬ã—ã€æœ€é©æ‰‹ã‚’è¿”ã™
        
        Args:
            battle_state: ç¾åœ¨ã®ãƒãƒˆãƒ«çŠ¶æ…‹
            verbose: è©³ç´°ãƒ­ã‚°ã‚’å‡ºåŠ›ã™ã‚‹ã‹
        
        Returns:
            {
                "player_a_win_rate": float,      # Player Aã®å‹ç‡ (0.0-1.0)
                "player_b_win_rate": float,      # Player Bã®å‹ç‡
                "optimal_action": TurnAction,    # æœ€é©ãªè¡Œå‹•ã‚»ãƒƒãƒˆ
                "optimal_action_win_rate": float,# æœ€é©æ‰‹ã®å‹ç‡
                "action_win_rates": Dict,        # å„è¡Œå‹•ã®å‹ç‡åˆ†å¸ƒ
                "total_rollouts": int,           # å®Ÿè¡Œã—ãŸrolloutæ•°
                "avg_turns_per_rollout": float   # å¹³å‡ã‚¿ãƒ¼ãƒ³æ•°
            }
        """
        # åˆæ³•æ‰‹ã‚’åˆ—æŒ™
        legal_actions = self._get_legal_actions(battle_state)
        
        if not legal_actions:
            # åˆæ³•æ‰‹ãŒãªã„å ´åˆ (ãƒãƒˆãƒ«çµ‚äº†æ¸ˆã¿)
            return self._evaluate_terminal_state(battle_state)
        
        if verbose:
            print(f"ğŸ” Monte Carlo Search: {len(legal_actions)} legal actions found")
        
        # å„è¡Œå‹•ã®å‹åˆ©æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
        action_stats = {
            i: {"wins": 0, "total": 0, "avg_turns": 0}
            for i in range(len(legal_actions))
        }
        
        # å„è¡Œå‹•ã«ã¤ã„ã¦ rollouts ã‚’å®Ÿè¡Œ
        trials_per_action = max(1, self.n_rollouts // len(legal_actions))
        total_turns = 0
        
        for action_idx, action in enumerate(legal_actions):
            if verbose and action_idx % 5 == 0:
                print(f"  Testing action {action_idx + 1}/{len(legal_actions)}...")
            
            for trial in range(trials_per_action):
                # ãƒãƒˆãƒ«ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
                winner, turns_taken = self._simulate_battle(battle_state, action)
                
                action_stats[action_idx]["total"] += 1
                action_stats[action_idx]["avg_turns"] += turns_taken
                total_turns += turns_taken
                
                if winner == "player_a":
                    action_stats[action_idx]["wins"] += 1
                
                self.total_simulations += 1
        
        # å‹ç‡ã‚’è¨ˆç®—
        action_win_rates = {}
        for action_idx, stats in action_stats.items():
            if stats["total"] > 0:
                win_rate = stats["wins"] / stats["total"]
                action_win_rates[action_idx] = win_rate
                action_stats[action_idx]["avg_turns"] = stats["avg_turns"] / stats["total"]
        
        # æœ€é©æ‰‹ã‚’ç‰¹å®š
        best_action_idx = max(action_win_rates, key=action_win_rates.get)
        best_action = legal_actions[best_action_idx]
        best_win_rate = action_win_rates[best_action_idx]
        
        if verbose:
            print(f"âœ… Best action: {best_action_idx} with win rate {best_win_rate:.2%}")
        
        return {
            "player_a_win_rate": best_win_rate,
            "player_b_win_rate": 1.0 - best_win_rate,
            "optimal_action": best_action,
            "optimal_action_win_rate": best_win_rate,
            "action_win_rates": action_win_rates,
            "total_rollouts": self.n_rollouts,
            "avg_turns_per_rollout": total_turns / self.n_rollouts if self.n_rollouts > 0 else 0,
            "action_stats": action_stats,
            "legal_actions": legal_actions
        }
    
    def _simulate_battle(
        self,
        initial_state: BattleState,
        first_action: TurnAction
    ) -> Tuple[str, int]:
        """
        ãƒãƒˆãƒ«ã‚’æœ€å¾Œã¾ã§ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        
        Args:
            initial_state: é–‹å§‹æ™‚ã®ç›¤é¢
            first_action: æœ€åˆã®ã‚¿ãƒ¼ãƒ³ã®è¡Œå‹•
        
        Returns:
            (winner, turns_taken)
            winner: "player_a" or "player_b"
            turns_taken: ã‹ã‹ã£ãŸã‚¿ãƒ¼ãƒ³æ•°
        """
        # ç¾åœ¨ã®çŠ¶æ…‹ã‚’ã‚³ãƒ”ãƒ¼ (å…ƒã®çŠ¶æ…‹ã‚’ç ´å£Šã—ãªã„)
        current_state = self._copy_state(initial_state)
        
        # æœ€åˆã®ã‚¿ãƒ¼ãƒ³ã‚’å®Ÿè¡Œ
        current_state = self._apply_action(current_state, first_action)
        turns = 1
        
        # ãƒãƒˆãƒ«ãŒçµ‚äº†ã™ã‚‹ã¾ã§ãƒ©ãƒ³ãƒ€ãƒ ãªæ‰‹ã‚’æ‰“ã¡ç¶šã‘ã‚‹
        while turns < self.max_turns:
            # ãƒãƒˆãƒ«çµ‚äº†åˆ¤å®š
            winner = self._check_winner(current_state)
            if winner is not None:
                return winner, turns
            
            # ãƒ©ãƒ³ãƒ€ãƒ ãªè¡Œå‹•ã‚’é¸æŠ
            legal_actions = self._get_legal_actions(current_state)
            if not legal_actions:
                # åˆæ³•æ‰‹ãŒãªã„ = å¼•ãåˆ†ã‘ (ç¨€)
                return "player_a" if random.random() < 0.5 else "player_b", turns
            
            random_action = random.choice(legal_actions)
            current_state = self._apply_action(current_state, random_action)
            turns += 1
        
        # æœ€å¤§ã‚¿ãƒ¼ãƒ³æ•°ã«é”ã—ãŸå ´åˆã€ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯è©•ä¾¡ã§å‹è€…ã‚’æ±ºå®š
        if self.use_heuristic:
            heuristic_score = self._evaluate_heuristic(current_state)
            winner = "player_a" if heuristic_score > 0 else "player_b"
        else:
            winner = "player_a" if random.random() < 0.5 else "player_b"
        
        return winner, turns
    
    def _get_legal_actions(self, state: BattleState) -> List[TurnAction]:
        """
        ç¾åœ¨ã®ç›¤é¢ã‹ã‚‰åˆæ³•æ‰‹ã‚’åˆ—æŒ™
        
        VGCãƒ€ãƒ–ãƒ«ãƒãƒˆãƒ«ã®å ´åˆ:
        - å„ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã¯2ä½“ã®ãƒã‚±ãƒ¢ãƒ³ã‚’å ´ã«å‡ºã—ã¦ã„ã‚‹
        - å„ã‚¿ãƒ¼ãƒ³ã€2ä½“åˆ†ã®è¡Œå‹•ã‚’åŒæ™‚ã«é¸æŠ
        - è¡Œå‹•: æŠ€ã‚’ä½¿ã†ã€äº¤ä»£ã™ã‚‹ã€ãƒ†ãƒ©ã‚¹ã‚¿ãƒ«ã™ã‚‹
        
        Phase 1å®Ÿè£…:
        - state.legal_actions ã‹ã‚‰ ActionCandidate ã‚’å–å¾—
        - ActionCandidate ã‚’ TurnAction ã«å¤‰æ›
        """
        legal_actions = []
        
        # Player Aã®åˆæ³•æ‰‹ã‚’å–å¾—
        player_a_candidates = state.legal_actions.get("A", [])
        
        if not player_a_candidates:
            # Fallback: å ´ã®ãƒã‚±ãƒ¢ãƒ³ã®æŠ€ã‚’åˆ—æŒ™
            player_a_candidates = self._generate_fallback_actions(state.player_a)
        
        # ç°¡ç•¥åŒ–: å„ãƒã‚±ãƒ¢ãƒ³ã®æœ€åˆã®æŠ€ã®ã¿ã‚’è€ƒæ…® (Phase 1)
        # æœ¬æ¥ã¯å…¨ã¦ã®æŠ€ã®çµ„ã¿åˆã‚ã›ã‚’è€ƒæ…®ã™ã¹ãã ãŒã€è¨ˆç®—é‡å‰Šæ¸›ã®ãŸã‚
        for candidate in player_a_candidates[:10]:  # æœ€åˆã®10æ‰‹ã®ã¿
            action = TurnAction(
                player_a_actions=[
                    Action(
                        type="move",
                        pokemon_slot=candidate.slot,
                        move_name=candidate.move,
                        target_slot=self._parse_target(candidate.target)
                    )
                ],
                player_b_actions=[
                    Action(
                        type="move",
                        pokemon_slot=0,
                        move_name="tackle",  # ãƒ€ãƒŸãƒ¼
                        target_slot=0
                    )
                ]
            )
            legal_actions.append(action)
        
        # æœ€ä½1ã¤ã¯è¿”ã™
        if not legal_actions:
            legal_actions = self._generate_dummy_actions(state)
        
        return legal_actions
    
    def _generate_fallback_actions(self, player: PlayerState) -> List[ActionCandidate]:
        """legal_actions ãŒç©ºã®å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
        actions = []
        for slot, pokemon in enumerate(player.active):
            if pokemon.moves:
                for move in pokemon.moves[:2]:  # æœ€åˆã®2ã¤ã®æŠ€
                    actions.append(
                        ActionCandidate(
                            actor=pokemon.name,
                            slot=slot,
                            move=move,
                            target=None
                        )
                    )
        return actions
    
    def _generate_dummy_actions(self, state: BattleState) -> List[TurnAction]:
        """å®Œå…¨ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒ€ãƒŸãƒ¼è¡Œå‹•ã‚’ç”Ÿæˆ"""
        return [
            TurnAction(
                player_a_actions=[
                    Action(type="move", pokemon_slot=0, move_name="tackle", target_slot=2)
                ],
                player_b_actions=[
                    Action(type="move", pokemon_slot=2, move_name="tackle", target_slot=0)
                ]
            )
        ]
    
    def _parse_target(self, target: Optional[str]) -> int:
        """å¯¾è±¡ã‚’ slot ç•ªå·ã«å¤‰æ›"""
        if target is None:
            return 2  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ç›¸æ‰‹ã®å·¦å´
        # TODO: å®Ÿéš›ã®ã‚¿ãƒ¼ã‚²ãƒƒãƒˆè§£æ
        return 2
    
    def _apply_action(
        self,
        state: BattleState,
        action: TurnAction
    ) -> BattleState:
        """
        è¡Œå‹•ã‚’é©ç”¨ã—ã€æ–°ã—ã„çŠ¶æ…‹ã‚’è¿”ã™
        
        Phase 1å®Ÿè£…:
        - ç°¡æ˜“ãƒ€ãƒ¡ãƒ¼ã‚¸è¨ˆç®— (ãƒ©ãƒ³ãƒ€ãƒ 10-30%)
        - HPã‚’æ¸›ã‚‰ã™
        - å€’ã‚ŒãŸãƒã‚±ãƒ¢ãƒ³ã®å‡¦ç†
        
        Phase 2ä»¥é™:
        - smogon_calc_wrapper ã‚’ä½¿ã£ãŸæ­£ç¢ºãªãƒ€ãƒ¡ãƒ¼ã‚¸è¨ˆç®—
        - é€Ÿåº¦åˆ¤å®š
        - çŠ¶æ…‹ç•°å¸¸
        - å¤©å€™ãƒ»ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰åŠ¹æœ
        """
        new_state = copy.deepcopy(state)
        
        # Player Aã®è¡Œå‹•ã‚’é©ç”¨
        for act in action.player_a_actions:
            if act.type == "move" and act.target_slot is not None:
                # ç°¡æ˜“ãƒ€ãƒ¡ãƒ¼ã‚¸: 10-30%ã®ãƒ©ãƒ³ãƒ€ãƒ ãƒ€ãƒ¡ãƒ¼ã‚¸
                damage = random.uniform(0.1, 0.3)
                self._apply_damage(new_state, act.target_slot, damage)
        
        # Player Bã®è¡Œå‹•ã‚’é©ç”¨
        for act in action.player_b_actions:
            if act.type == "move" and act.target_slot is not None:
                damage = random.uniform(0.1, 0.3)
                self._apply_damage(new_state, act.target_slot, damage)
        
        # å€’ã‚ŒãŸãƒã‚±ãƒ¢ãƒ³ã®å‡¦ç†
        self._remove_fainted(new_state)
        
        return new_state
    
    def _apply_damage(self, state: BattleState, target_slot: int, damage_fraction: float):
        """æŒ‡å®šã—ãŸslotã®ãƒã‚±ãƒ¢ãƒ³ã«ãƒ€ãƒ¡ãƒ¼ã‚¸ã‚’ä¸ãˆã‚‹"""
        if target_slot < 2:
            # Player Aã®ãƒã‚±ãƒ¢ãƒ³
            if target_slot < len(state.player_a.active):
                pokemon = state.player_a.active[target_slot]
                pokemon.hp_fraction = max(0.0, pokemon.hp_fraction - damage_fraction)
        else:
            # Player Bã®ãƒã‚±ãƒ¢ãƒ³
            b_slot = target_slot - 2
            if b_slot < len(state.player_b.active):
                pokemon = state.player_b.active[b_slot]
                pokemon.hp_fraction = max(0.0, pokemon.hp_fraction - damage_fraction)
    
    def _remove_fainted(self, state: BattleState):
        """å€’ã‚ŒãŸãƒã‚±ãƒ¢ãƒ³ã‚’å ´ã‹ã‚‰é™¤å¤–"""
        state.player_a.active = [p for p in state.player_a.active if p.hp_fraction > 0]
        state.player_b.active = [p for p in state.player_b.active if p.hp_fraction > 0]
    
    def _check_winner(self, state: BattleState) -> Optional[str]:
        """
        ãƒãƒˆãƒ«çµ‚äº†åˆ¤å®š
        
        Returns:
            "player_a": Player Aã®å‹åˆ©
            "player_b": Player Bã®å‹åˆ©
            None: ãƒãƒˆãƒ«ç¶™ç¶šä¸­
        """
        # Player Aã®å ´ã®ãƒã‚±ãƒ¢ãƒ³ãŒå…¨æ»…
        if not state.player_a.active or all(p.hp_fraction <= 0 for p in state.player_a.active):
            # æ§ãˆãŒã„ãªã„å ´åˆã¯è² ã‘
            if not state.player_a.reserves:
                return "player_b"
        
        # Player Bã®å ´ã®ãƒã‚±ãƒ¢ãƒ³ãŒå…¨æ»…
        if not state.player_b.active or all(p.hp_fraction <= 0 for p in state.player_b.active):
            if not state.player_b.reserves:
                return "player_a"
        
        return None
    
    def _evaluate_heuristic(self, state: BattleState) -> float:
        """
        ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯è©•ä¾¡
        
        HeuristicEvaluator ã‚’ä½¿ç”¨ã—ã¦ã€ç¾åœ¨ã®ç›¤é¢ã®æœ‰åˆ©åº¦ã‚’è©•ä¾¡ã™ã‚‹ã€‚
        
        Returns:
            > 0: Player Aæœ‰åˆ©
            < 0: Player Bæœ‰åˆ©
            = 0: äº’è§’
        """
        try:
            # HeuristicEvaluator ã§è©•ä¾¡
            evaluation = self.evaluator.evaluate(state)
            
            # å‹ç‡ã‹ã‚‰æœ‰åˆ©åº¦ã‚¹ã‚³ã‚¢ã«å¤‰æ›
            # win_rate: 0.0-1.0 â†’ score: -5.0 ~ +5.0
            win_rate_a = evaluation.player_a.win_rate
            score = (win_rate_a - 0.5) * 10  # 0.5 (äº’è§’) ã‚’ 0.0 ã«ã€0.0/1.0 ã‚’ Â±5.0 ã«
            
            return score
        except Exception:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: HPæ¯”è¼ƒ
            hp_a = sum(p.hp_fraction for p in state.player_a.active)
            hp_b = sum(p.hp_fraction for p in state.player_b.active)
            return hp_a - hp_b
    
    def _evaluate_terminal_state(self, state: BattleState) -> Dict[str, Any]:
        """
        çµ‚äº†çŠ¶æ…‹ã®è©•ä¾¡ (åˆæ³•æ‰‹ãŒãªã„å ´åˆ)
        """
        winner = self._check_winner(state)
        
        if winner == "player_a":
            return {
                "player_a_win_rate": 1.0,
                "player_b_win_rate": 0.0,
                "optimal_action": None,
                "optimal_action_win_rate": 1.0,
                "action_win_rates": {},
                "total_rollouts": 0,
                "avg_turns_per_rollout": 0
            }
        elif winner == "player_b":
            return {
                "player_a_win_rate": 0.0,
                "player_b_win_rate": 1.0,
                "optimal_action": None,
                "optimal_action_win_rate": 0.0,
                "action_win_rates": {},
                "total_rollouts": 0,
                "avg_turns_per_rollout": 0
            }
        else:
            # å¼•ãåˆ†ã‘ (ç¨€)
            return {
                "player_a_win_rate": 0.5,
                "player_b_win_rate": 0.5,
                "optimal_action": None,
                "optimal_action_win_rate": 0.5,
                "action_win_rates": {},
                "total_rollouts": 0,
                "avg_turns_per_rollout": 0
            }
    
    def _copy_state(self, state: BattleState) -> BattleState:
        """
        ãƒãƒˆãƒ«çŠ¶æ…‹ã®ãƒ‡ã‚£ãƒ¼ãƒ—ã‚³ãƒ”ãƒ¼
        """
        return copy.deepcopy(state)
    
    def get_statistics(self) -> Dict[str, Any]:
        """
        å®Ÿè¡Œçµ±è¨ˆã‚’å–å¾—
        """
        return {
            "total_simulations": self.total_simulations,
            "cache_hits": self.cache_hits,
            "cache_hit_rate": self.cache_hits / max(1, self.total_simulations)
        }
