"""
Phase 2: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ - ãƒªãƒ—ãƒ¬ã‚¤ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰

ç›®çš„: Pokemon Showdownå…¬å¼ã‚µã‚¤ãƒˆã‹ã‚‰å¯¾æˆ¦ãƒªãƒ—ãƒ¬ã‚¤ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã€
     å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ§‹ç¯‰ã™ã‚‹ã€‚

å®Ÿè¡Œæ–¹æ³•:
    python scripts/phase2_download_replays.py --format gen9ou --count 100

å¼•æ•°:
    --format: å¯¾æˆ¦ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ (gen9ou, gen9vgc2024, ãªã©)
    --count: ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ãƒªãƒ—ãƒ¬ã‚¤æ•°
    --min-rating: æœ€ä½ãƒ¬ãƒ¼ãƒ†ã‚£ãƒ³ã‚° (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 1500)
    --output: ä¿å­˜å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: data/replays/)
"""

import argparse
import asyncio
import json
import re
from pathlib import Path
from typing import List, Dict, Any
from datetime import datetime

try:
    import aiohttp
    from bs4 import BeautifulSoup
except ImportError:
    print("âŒ å¿…è¦ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“")
    print("ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«: pip install aiohttp beautifulsoup4 lxml")
    exit(1)


class ReplayDownloader:
    """Pokemon Showdownã®ãƒªãƒ—ãƒ¬ã‚¤ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    
    BASE_URL = "https://replay.pokemonshowdown.com"
    
    def __init__(self, format_id: str, min_rating: int = 1500):
        self.format_id = format_id
        self.min_rating = min_rating
        self.downloaded_count = 0
        self.failed_count = 0
    
    async def search_replays(
        self,
        session: aiohttp.ClientSession,
        page: int = 1
    ) -> List[str]:
        """
        æŒ‡å®šãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®ãƒªãƒ—ãƒ¬ã‚¤ã‚’æ¤œç´¢
        
        Returns:
            ãƒªãƒ—ãƒ¬ã‚¤IDã®ãƒªã‚¹ãƒˆ
        """
        # æ¤œç´¢APIã‚’ä½¿ç”¨ï¼ˆãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³å¯¾å¿œï¼‰
        url = f"{self.BASE_URL}/search.json"
        params = {
            "format": self.format_id,
            "page": page,
        }
        
        try:
            async with session.get(url, params=params) as response:
                if response.status != 200:
                    print(f"âš ï¸  æ¤œç´¢ã‚¨ãƒ©ãƒ¼ (ãƒšãƒ¼ã‚¸ {page}): HTTP {response.status}")
                    print(f"   URL: {url}?format={self.format_id}&page={page}")
                    return []
                
                data = await response.json()
                
                # JSONãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰ãƒªãƒ—ãƒ¬ã‚¤IDã‚’æŠ½å‡º
                replays = data if isinstance(data, list) else []
                replay_ids = []
                
                for item in replays:
                    if isinstance(item, dict):
                        replay_id = item.get("id", "")
                        if replay_id:
                            replay_ids.append(replay_id)
                    elif isinstance(item, str):
                        replay_ids.append(item)
                
                print(f"ğŸ“„ ãƒšãƒ¼ã‚¸ {page}: {len(replay_ids)}ä»¶ã®ãƒªãƒ—ãƒ¬ã‚¤ã‚’ç™ºè¦‹")
                return replay_ids
                
        except Exception as e:
            print(f"âŒ æ¤œç´¢ã‚¨ãƒ©ãƒ¼ (ãƒšãƒ¼ã‚¸ {page}): {e}")
            import traceback
            traceback.print_exc()
            return []
    
    async def download_replay(
        self,
        session: aiohttp.ClientSession,
        replay_id: str
    ) -> Dict[str, Any] | None:
        """
        ãƒªãƒ—ãƒ¬ã‚¤ã®è©³ç´°ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        
        Returns:
            ãƒªãƒ—ãƒ¬ã‚¤ãƒ‡ãƒ¼ã‚¿ (JSONå½¢å¼) ã¾ãŸã¯ None
        """
        url = f"{self.BASE_URL}/{replay_id}.json"
        
        try:
            async with session.get(url) as response:
                if response.status != 200:
                    self.failed_count += 1
                    return None
                
                data = await response.json()
                
                # ãƒ¬ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ãƒã‚§ãƒƒã‚¯
                rating = data.get("rating")
                if rating is None or rating < self.min_rating:
                    return None
                
                self.downloaded_count += 1
                print(f"âœ… [{self.downloaded_count}] {replay_id} (Rating: {rating})")
                
                return {
                    "id": replay_id,
                    "format": data.get("format"),
                    "rating": rating,
                    "uploadtime": data.get("uploadtime"),
                    "log": data.get("log", ""),
                    "players": data.get("players", []),
                    "winner": data.get("winner"),
                }
                
        except Exception as e:
            self.failed_count += 1
            print(f"âŒ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¤±æ•— ({replay_id}): {e}")
            return None
    
    async def download_batch(
        self,
        target_count: int,
        output_dir: Path
    ) -> int:
        """
        æŒ‡å®šæ•°ã®ãƒªãƒ—ãƒ¬ã‚¤ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        
        Returns:
            ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æˆåŠŸæ•°
        """
        output_dir.mkdir(parents=True, exist_ok=True)
        
        async with aiohttp.ClientSession() as session:
            page = 1
            replays_data = []
            
            while self.downloaded_count < target_count:
                print(f"\n{'='*60}")
                print(f"ãƒšãƒ¼ã‚¸ {page} ã‚’æ¤œç´¢ä¸­...")
                print(f"{'='*60}")
                
                # ãƒªãƒ—ãƒ¬ã‚¤IDã‚’æ¤œç´¢
                replay_ids = await self.search_replays(session, page)
                
                if not replay_ids:
                    print("âš ï¸  ã“ã‚Œä»¥ä¸Šã®ãƒªãƒ—ãƒ¬ã‚¤ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                    break
                
                # å„ãƒªãƒ—ãƒ¬ã‚¤ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                for replay_id in replay_ids:
                    if self.downloaded_count >= target_count:
                        break
                    
                    replay_data = await self.download_replay(session, replay_id)
                    
                    if replay_data:
                        replays_data.append(replay_data)
                        
                        # å®šæœŸçš„ã«ä¿å­˜
                        if len(replays_data) % 10 == 0:
                            self._save_batch(replays_data, output_dir)
                    
                    # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–
                    await asyncio.sleep(0.5)
                
                page += 1
            
            # æœ€çµ‚ä¿å­˜
            if replays_data:
                self._save_batch(replays_data, output_dir)
        
        return self.downloaded_count
    
    def _save_batch(self, replays_data: List[Dict[str, Any]], output_dir: Path):
        """ãƒãƒƒãƒã§ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"{self.format_id}_{timestamp}.json"
        filepath = output_dir / filename
        
        with open(filepath, "w", encoding="utf-8") as f:
            json.dump(replays_data, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ ä¿å­˜: {filepath} ({len(replays_data)}ä»¶)")


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(
        description="Pokemon Showdownã®ãƒªãƒ—ãƒ¬ã‚¤ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"
    )
    parser.add_argument(
        "--format",
        type=str,
        default="gen9ou",
        help="å¯¾æˆ¦ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ (ä¾‹: gen9ou, gen9vgc2024regh)",
    )
    parser.add_argument(
        "--count",
        type=int,
        default=100,
        help="ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ãƒªãƒ—ãƒ¬ã‚¤æ•°",
    )
    parser.add_argument(
        "--min-rating",
        type=int,
        default=1500,
        help="æœ€ä½ãƒ¬ãƒ¼ãƒ†ã‚£ãƒ³ã‚°",
    )
    parser.add_argument(
        "--output",
        type=Path,
        default=Path("data/replays"),
        help="ä¿å­˜å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª",
    )
    return parser.parse_args()


async def main():
    args = parse_args()
    
    print("=" * 70)
    print("Phase 2: ãƒªãƒ—ãƒ¬ã‚¤ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
    print("=" * 70)
    print()
    print(f"ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ: {args.format}")
    print(f"ç›®æ¨™ä»¶æ•°: {args.count}ä»¶")
    print(f"æœ€ä½ãƒ¬ãƒ¼ãƒ†ã‚£ãƒ³ã‚°: {args.min_rating}")
    print(f"ä¿å­˜å…ˆ: {args.output}")
    print()
    
    downloader = ReplayDownloader(args.format, args.min_rating)
    
    try:
        downloaded = await downloader.download_batch(args.count, args.output)
        
        print()
        print("=" * 70)
        print("ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†")
        print("=" * 70)
        print(f"æˆåŠŸ: {downloaded}ä»¶")
        print(f"å¤±æ•—: {downloader.failed_count}ä»¶")
        print(f"ä¿å­˜å…ˆ: {args.output}")
        print()
        print("âœ… Phase 2 å®Œäº†ï¼")
        print()
        
    except KeyboardInterrupt:
        print()
        print("âš ï¸  ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã£ã¦ä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
        print(f"ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿: {downloader.downloaded_count}ä»¶")
    except Exception as e:
        print()
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        raise


if __name__ == "__main__":
    asyncio.run(main())
