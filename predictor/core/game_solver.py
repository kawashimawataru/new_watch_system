"""
GameSolver - æ·±ã•åˆ¶é™ã‚²ãƒ¼ãƒ æ¢ç´¢

PokÃ©Champå‹ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®æ¢ç´¢ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã€‚
U(a,b) æ¨å®š + Quantal Response ã§è¡Œå‹•åˆ†å¸ƒã‚’ç”Ÿæˆã€‚

References:
- PokÃ©Champ: https://arxiv.org/abs/2503.04094
"""

from __future__ import annotations

import math
import numpy as np
from dataclasses import dataclass, field
from typing import Any, Dict, List, Literal, Optional, Tuple

from predictor.engine.simulator_adapter import (
    ActionOrder,
    JointAction,
    SimulatorAdapter,
    get_simulator,
)
from predictor.core.candidate_generator import (
    CandidateGenerator,
    CandidateScore,
    get_candidate_generator,
)
from predictor.core.evaluator import (
    Evaluator,
    get_evaluator,
)

try:
    from poke_env.environment.double_battle import DoubleBattle
except ImportError:
    try:
        from poke_env.battle import DoubleBattle
    except ImportError:
        DoubleBattle = None


# ============================================================================
# è¨­å®š
# ============================================================================

@dataclass
class SolverConfig:
    """æ¢ç´¢ã®è¨­å®šï¼ˆè¶…é«˜ç²¾åº¦ç‰ˆï¼‰"""
    depth: int = 8                  # æ¢ç´¢æ·±ã•ï¼ˆã‚¿ãƒ¼ãƒ³ï¼‰- 6â†’8
    n_samples: int = 500            # ä¹±æ•°ã‚µãƒ³ãƒ—ãƒ«æ•° - 200â†’500
    top_k_self: int = 80            # è‡ªåˆ†å€™è£œæ•° - 50â†’80
    top_k_opp: int = 80             # ç›¸æ‰‹å€™è£œæ•° - 50â†’80
    tau: float = 0.25               # ç›¸æ‰‹ã®Quantalæ¸©åº¦
    tau_self: float = 0.30          # è‡ªåˆ†ã®Quantalæ¸©åº¦
    llm_weight: float = 0.4         # LLMåˆ†å¸ƒã®é‡ã¿ï¼ˆÎ»ï¼‰
    use_llm: bool = False           # LLMã‚’ä½¿ã†ã‹


# ============================================================================
# å‡ºåŠ›ãƒ‡ãƒ¼ã‚¿æ§‹é€ 
# ============================================================================

@dataclass
class ActionProbability:
    """è¡Œå‹•ã¨ç¢ºç‡"""
    action: JointAction
    probability: float
    delta: Optional[float] = None   # æœ€å–„æ‰‹ã¨ã®å·®åˆ†
    tags: List[str] = field(default_factory=list)
    
    def __str__(self) -> str:
        return f"{self.action} (p={self.probability:.1%}, Î”={self.delta or 0:+.1%})"


@dataclass
class SwingPoint:
    """åˆ†å²ç‚¹"""
    description: str
    impact: float                   # å‹ç‡ã¸ã®å½±éŸ¿


@dataclass
class SolveResult:
    """æ¢ç´¢çµæœ"""
    win_prob: float                             # æœŸå¾…å‹ç‡
    self_dist: List[ActionProbability]          # è‡ªåˆ†ã®è¡Œå‹•åˆ†å¸ƒ
    opp_dist: List[ActionProbability]           # ç›¸æ‰‹ã®è¡Œå‹•åˆ†å¸ƒ
    u_matrix: Optional[np.ndarray] = None       # U(a,b) è¡Œåˆ—
    swing_points: List[SwingPoint] = field(default_factory=list)
    breakdown: Dict[str, float] = field(default_factory=dict)


# ============================================================================
# Quantal Response
# ============================================================================

def quantal_response(utilities: np.ndarray, tau: float) -> np.ndarray:
    """
    Quantal Response åˆ†å¸ƒ
    
    Ï€(a) âˆ exp(U(a) / Ï„)
    
    Args:
        utilities: å„è¡Œå‹•ã®æœŸå¾…åŠ¹ç”¨
        tau: æ¸©åº¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆå°â†’é‹­ã„ã€å¤§â†’ä¸€æ§˜ã«è¿‘ã„ï¼‰
        
    Returns:
        ç¢ºç‡åˆ†å¸ƒï¼ˆåˆè¨ˆ1ï¼‰
    """
    if tau <= 0:
        tau = 0.01
    
    logits = utilities / tau
    logits -= np.max(logits)  # æ•°å€¤å®‰å®šåŒ–
    exp_logits = np.exp(logits)
    
    total = exp_logits.sum()
    if total == 0:
        return np.ones_like(utilities) / len(utilities)
    
    return exp_logits / total


def sigmoid(x: float) -> float:
    """ã‚·ã‚°ãƒ¢ã‚¤ãƒ‰é–¢æ•°"""
    return 1.0 / (1.0 + math.exp(-x))


# ============================================================================
# GameSolver
# ============================================================================

class GameSolver:
    """
    æ·±ã•åˆ¶é™ã‚²ãƒ¼ãƒ æ¢ç´¢
    
    1. å€™è£œç”Ÿæˆï¼ˆCandidateGeneratorï¼‰
    2. U(a,b) æ¨å®šï¼ˆæ·±ã•d, ã‚µãƒ³ãƒ—ãƒ«Nï¼‰
    3. Quantal Response ã§åˆ†å¸ƒç”Ÿæˆ
    4. å‹ç‡ãƒ»åˆ†å²ç‚¹ã‚’è¨ˆç®—
    """
    
    def __init__(
        self,
        config: Optional[SolverConfig] = None,
        simulator: Optional[SimulatorAdapter] = None,
        generator: Optional[CandidateGenerator] = None,
        evaluator: Optional[Evaluator] = None,
        llm_client: Optional[Any] = None,
    ):
        self.config = config or SolverConfig()
        self.simulator = simulator or get_simulator()
        self.generator = generator or get_candidate_generator()
        self.evaluator = evaluator or get_evaluator()
        self.llm = llm_client
        
        # Transposition Table: åŒä¸€å±€é¢ã®å†è¨ˆç®—ã‚’é¿ã‘ã‚‹ã‚­ãƒ£ãƒƒã‚·ãƒ¥
        # key: (battle_hash, self_action_key, opp_action_key, depth)
        # value: utility
        self._transposition_table: Dict[Tuple, float] = {}
        self._cache_hits = 0
        self._cache_misses = 0
    
    def solve(self, battle: DoubleBattle, recommended_moves: Optional[Dict[int, set]] = None) -> SolveResult:
        """
        æ¢ç´¢ã‚’å®Ÿè¡Œ
        
        Args:
            battle: poke-envã®DoubleBattleã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
            recommended_moves: TurnAdvisorã‹ã‚‰ã®æ¨å¥¨æŠ€ {slot: set(move_ids)}
        
        Returns:
            SolveResult
        """
        # 1. å€™è£œç”Ÿæˆ
        # Phase 10: LLMæ¨å¥¨ã‚’è€ƒæ…®ã™ã‚‹ãŸã‚ã€é€šå¸¸ã‚ˆã‚Šå¤šãå€™è£œã‚’ç”Ÿæˆã—ã¦ã‹ã‚‰ãƒœãƒ¼ãƒŠã‚¹åŠ ç®—ãƒ»åœ§ç¸®
        temp_top_k = self.config.top_k_self * 2 if recommended_moves else self.config.top_k_self
        
        self_candidates = self.generator.generate(
            battle, "self", temp_top_k
        )
        opp_candidates = self.generator.generate(
            battle, "opp", self.config.top_k_opp
        )
        
        # ============= Phase 10: TurnAdvisor æ¨å¥¨ãƒœãƒ¼ãƒŠã‚¹ =============
        # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã§ã¯ãªãã‚¹ã‚³ã‚¢ãƒœãƒ¼ãƒŠã‚¹ã¨ã—ã¦æ‰±ã„ã€
        # ã€Œãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã§è©•ä¾¡ä½ã„ãŒåˆç†çš„ã€ãªæ‰‹ã‚’æ•‘æ¸ˆã™ã‚‹
        if recommended_moves:
            bonus_score = 2.0  # å¤§ãã‚ã®ãƒœãƒ¼ãƒŠã‚¹
            
            for cand in self_candidates:
                # slot0, slot1 ã®æŠ€ãŒãã‚Œãã‚Œæ¨å¥¨ãƒªã‚¹ãƒˆã«å«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                # éƒ¨åˆ†ä¸€è‡´ã§ã‚‚ãƒœãƒ¼ãƒŠã‚¹ï¼ˆç‰‡æ–¹ã§ã‚‚åˆã£ã¦ã„ã‚Œã°0.5å€ãªã©ï¼‰
                
                match_count = 0
                
                if cand.action.slot0 and cand.action.slot0.move_id:
                    slot0_moves = recommended_moves.get(0, set())
                    if slot0_moves and cand.action.slot0.move_id.lower() in slot0_moves:
                        match_count += 1
                
                if cand.action.slot1 and cand.action.slot1.move_id:
                    slot1_moves = recommended_moves.get(1, set())
                    if slot1_moves and cand.action.slot1.move_id.lower() in slot1_moves:
                        match_count += 1
                
                if match_count > 0:
                    # ä¸¡æ–¹ä¸€è‡´ãªã‚‰æº€é¡ã€ç‰‡æ–¹ãªã‚‰åŠé¡
                    bonus = bonus_score if match_count == 2 else (bonus_score * 0.5)
                    cand.score += bonus
                    cand.tags.append(f"llm_bonus_{match_count}")
            
            # ãƒœãƒ¼ãƒŠã‚¹åŠ ç®—å¾Œã«å†ã‚½ãƒ¼ãƒˆã—ã¦ Top-K ã«åœ§ç¸®
            self_candidates.sort(reverse=True)
            self_candidates = self_candidates[:self.config.top_k_self]
            
            print(f"  ğŸ¤– LLMãƒœãƒ¼ãƒŠã‚¹é©ç”¨: ä¸Šä½{len(self_candidates)}å€™è£œã‚’é¸å®š (ç”Ÿæˆæ•°: {temp_top_k})")
        
        if not self_candidates or not opp_candidates:
            # å€™è£œãŒãªã„å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
            return SolveResult(
                win_prob=0.5,
                self_dist=[],
                opp_dist=[],
            )
        
        # 2. U(a,b) æ¨å®š
        n_self = len(self_candidates)
        n_opp = len(opp_candidates)
        U = np.zeros((n_self, n_opp))
        
        for i, self_cand in enumerate(self_candidates):
            for j, opp_cand in enumerate(opp_candidates):
                U[i, j] = self._estimate_utility(
                    battle,
                    self_cand.action,
                    opp_cand.action,
                    depth=self.config.depth,
                    n_samples=self.config.n_samples,
                )
        
        # 3. ç›¸æ‰‹ã®åˆ†å¸ƒï¼ˆQuantal Responseï¼‰
        # ç›¸æ‰‹è¦–ç‚¹ã§ã¯ U ãŒåè»¢
        opp_utilities = -U.mean(axis=0)  # å„ b ã®å¹³å‡åŠ¹ç”¨
        opp_probs = quantal_response(opp_utilities, self.config.tau)
        
        # 4. è‡ªåˆ†ã®åˆ†å¸ƒ
        # ç›¸æ‰‹åˆ†å¸ƒã«å¯¾ã™ã‚‹æœŸå¾…åŠ¹ç”¨
        self_utilities = U @ opp_probs  # å„ a ã®æœŸå¾…åŠ¹ç”¨
        self_probs = quantal_response(self_utilities, self.config.tau_self)
        
        # 5. æœŸå¾…å‹ç‡
        expected_u = self_probs @ U @ opp_probs
        win_prob = sigmoid(expected_u)
        
        # 6. åˆ†å¸ƒã‚’æ•´å½¢
        best_self_value = self_utilities.max()
        self_dist = []
        for i, cand in enumerate(self_candidates):
            delta = self_utilities[i] - best_self_value
            self_dist.append(ActionProbability(
                action=cand.action,
                probability=float(self_probs[i]),
                delta=float(delta),
                tags=cand.tags,
            ))
        
        opp_dist = []
        for j, cand in enumerate(opp_candidates):
            opp_dist.append(ActionProbability(
                action=cand.action,
                probability=float(opp_probs[j]),
                tags=cand.tags,
            ))
        
        # ============= Phase 2: RiskAwareSolver èª¿æ•´ =============
        # çŠ¶æ³ã«å¿œã˜ã¦ Secure/Gamble ãƒ¢ãƒ¼ãƒ‰ã§ç¢ºç‡ã‚’èª¿æ•´
        try:
            from predictor.core.risk_aware_solver import RiskAwareSolver, ScoredCandidate
            risk_solver = RiskAwareSolver()
            mode = risk_solver.determine_mode(win_prob)
            
            # self_dist ã‚’ ScoredCandidate ã«å¤‰æ›
            scored_candidates = []
            for i, ap in enumerate(self_dist):
                # åˆ†æ•£ã‚’ç°¡æ˜“è¨ˆç®—ï¼ˆUè¡Œåˆ—ã®ãã®è¡Œã®åˆ†æ•£ï¼‰
                variance = float(np.var(U[i, :])) if i < len(U) else 0.0
                max_value = float(np.max(U[i, :])) if i < len(U) else 0.0
                min_value = float(np.min(U[i, :])) if i < len(U) else 0.0
                
                scored_candidates.append(ScoredCandidate(
                    action=ap.action,
                    expected_value=float(self_utilities[i]) if i < len(self_utilities) else 0.0,
                    variance=variance,
                    max_value=max_value,
                    min_value=min_value,
                    tags=ap.tags,
                ))
            
            # ãƒ¢ãƒ¼ãƒ‰ã«å¿œã˜ã¦èª¿æ•´
            if scored_candidates:
                adjusted = risk_solver.adjust_candidates(scored_candidates, win_prob)
                
                # èª¿æ•´å¾Œã®ã‚¹ã‚³ã‚¢ã§ç¢ºç‡ã‚’å†è¨ˆç®—
                adjusted_utilities = np.array([c.adjusted_score for c in adjusted])
                adjusted_probs = quantal_response(adjusted_utilities, self.config.tau_self)
                
                # self_dist ã‚’æ›´æ–°
                for i, cand in enumerate(adjusted):
                    for ap in self_dist:
                        if str(ap.action) == str(cand.action):
                            ap.tags.extend([t for t in cand.tags if t not in ap.tags])
                            break
        except Exception as e:
            pass  # RiskAwareSolver ãŒä½¿ãˆãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
        
        # ç¢ºç‡ã§ã‚½ãƒ¼ãƒˆ
        self_dist.sort(key=lambda x: x.probability, reverse=True)
        opp_dist.sort(key=lambda x: x.probability, reverse=True)
        
        # 7. åˆ†å²ç‚¹æ¤œå‡º
        swing_points = self._detect_swing_points(
            self_candidates, opp_candidates, U, self_probs, opp_probs
        )
        
        return SolveResult(
            win_prob=win_prob,
            self_dist=self_dist[:5],  # Top 5
            opp_dist=opp_dist[:5],
            u_matrix=U,
            swing_points=swing_points,
        )
    
    def _estimate_utility(
        self,
        battle: DoubleBattle,
        action_self: JointAction,
        action_opp: JointAction,
        depth: int,
        n_samples: int,
    ) -> float:
        """
        U(a, b) ã‚’æ¨å®šï¼ˆTransposition Table ã§ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼‰
        
        ç¾åœ¨ã¯æ·±ã•1ã®ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯è©•ä¾¡ã€‚
        å°†æ¥çš„ã«ã¯Showdowné·ç§»ã§ãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆã€‚
        """
        # ============= Transposition Table ã‚­ãƒ£ãƒƒã‚·ãƒ¥ =============
        # ã‚­ãƒ¼: (turn, self_action, opp_action)
        cache_key = (
            battle.turn,
            self._action_to_key(action_self),
            self._action_to_key(action_opp),
        )
        
        if cache_key in self._transposition_table:
            self._cache_hits += 1
            return self._transposition_table[cache_key]
        
        self._cache_misses += 1
        
        # ç°¡æ˜“å®Ÿè£…: ç¾åœ¨ã®çŠ¶æ…‹è©•ä¾¡ + è¡Œå‹•ã®ã‚¹ã‚³ã‚¢
        base_value = self.evaluator.evaluate(battle, "self")
        
        # è¡Œå‹•ã®ã‚¹ã‚³ã‚¢ã‚’åŠ å‘³ï¼ˆCandidateGeneratorã®ã‚¹ã‚³ã‚¢ã‚’å†åˆ©ç”¨ï¼‰
        self_score, _ = self.generator.scorer.score_joint_action(
            action_self, battle, "self"
        )
        opp_score, _ = self.generator.scorer.score_joint_action(
            action_opp, battle, "opp"
        )
        
        # æ­£è¦åŒ–ã—ã¦UtilityåŒ–
        utility = base_value + (self_score - opp_score) * 0.1
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
        self._transposition_table[cache_key] = utility
        
        return utility
    
    def _action_to_key(self, action: JointAction) -> str:
        """ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼ç”¨ã®æ–‡å­—åˆ—ã«å¤‰æ›"""
        if action is None:
            return "none"
        
        s0 = action.slot0
        s1 = action.slot1
        
        s0_key = f"{s0.action_type.value}:{s0.move_id or ''}:{s0.target or ''}" if s0 else "pass"
        s1_key = f"{s1.action_type.value}:{s1.move_id or ''}:{s1.target or ''}" if s1 else "pass"
        
        return f"{s0_key}|{s1_key}"
    
    def clear_cache(self):
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢ï¼ˆæ–°ã—ã„ã‚¿ãƒ¼ãƒ³é–‹å§‹æ™‚ã«å‘¼ã³å‡ºã—ï¼‰"""
        if self._cache_hits + self._cache_misses > 0:
            hit_rate = self._cache_hits / (self._cache_hits + self._cache_misses)
            print(f"  ğŸ“Š Transposition Table: hits={self._cache_hits}, misses={self._cache_misses}, rate={hit_rate:.1%}")
        
        self._transposition_table.clear()
        self._cache_hits = 0
        self._cache_misses = 0
    
    def _detect_swing_points(
        self,
        self_candidates: List[CandidateScore],
        opp_candidates: List[CandidateScore],
        U: np.ndarray,
        self_probs: np.ndarray,
        opp_probs: np.ndarray,
    ) -> List[SwingPoint]:
        """åˆ†å²ç‚¹ã‚’æ¤œå‡º"""
        swing_points = []
        
        # æœ€ã‚‚å½±éŸ¿ã®å¤§ãã„ç›¸æ‰‹è¡Œå‹•ã‚’æ¤œå‡º
        expected_u = self_probs @ U @ opp_probs
        
        for j, opp_cand in enumerate(opp_candidates):
            if opp_probs[j] > 0.1:  # ç¢ºç‡10%ä»¥ä¸Š
                # ã“ã®è¡Œå‹•ãŒæ¥ãŸå ´åˆã®Utility
                u_if_this = self_probs @ U[:, j]
                impact = sigmoid(u_if_this) - sigmoid(expected_u)
                
                if abs(impact) > 0.05:  # 5%ä»¥ä¸Šã®å½±éŸ¿
                    desc = f"ç›¸æ‰‹ãŒ{opp_cand.action.slot0}ã‚’é¸æŠ"
                    swing_points.append(SwingPoint(
                        description=desc,
                        impact=float(impact),
                    ))
        
        # è‡ªåˆ†ã®ä»£æ›¿æ‰‹ã®å½±éŸ¿
        best_self_idx = np.argmax(self_probs)
        for i, self_cand in enumerate(self_candidates):
            if i != best_self_idx and self_probs[i] > 0.05:
                u_if_this = U[i, :] @ opp_probs
                u_best = U[best_self_idx, :] @ opp_probs
                delta = sigmoid(u_if_this) - sigmoid(u_best)
                
                if abs(delta) > 0.05:
                    desc = f"ä»£ã‚ã‚Šã«{self_cand.action.slot0}ã‚’é¸æŠ"
                    swing_points.append(SwingPoint(
                        description=desc,
                        impact=float(delta),
                    ))
        
        # å½±éŸ¿é †ã§ã‚½ãƒ¼ãƒˆ
        swing_points.sort(key=lambda x: abs(x.impact), reverse=True)
        
        return swing_points[:3]  # Top 3


# ============================================================================
# ã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³
# ============================================================================

_solver: Optional[GameSolver] = None

def get_game_solver() -> GameSolver:
    """GameSolverã®ã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ã‚’å–å¾—"""
    global _solver
    if _solver is None:
        _solver = GameSolver()
    return _solver
