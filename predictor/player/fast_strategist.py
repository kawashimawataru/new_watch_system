"""
Fast-Laneæˆ¦ç•¥ã‚¨ãƒ³ã‚¸ãƒ³ (LightGBM)

10msä»¥å†…ã§å³æ™‚å‹ç‡æ¨å®šã‚’å®Ÿç¾ã™ã‚‹è»½é‡ãƒ¢ãƒ‡ãƒ«ã€‚
Phase 1ã§ã¯åŸºæœ¬çš„ãªç‰¹å¾´é‡ã®ã¿ã‚’ä½¿ç”¨ã—ã€é«˜é€Ÿæ¨è«–ã‚’å„ªå…ˆã€‚

Usage:
    strategist = FastStrategist.load("models/fast_lane.pkl")
    win_rate = strategist.predict(battle_state)
"""

import pickle
import time
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

import lightgbm as lgb
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split

from predictor.core.models import BattleState


@dataclass
class FastPrediction:
    """
    Fast-Laneã®äºˆæ¸¬çµæœ
    
    Attributes:
        p1_win_rate: P1ã®å‹ç‡ (0.0 ~ 1.0)
        inference_time_ms: æ¨è«–æ™‚é–“ (ãƒŸãƒªç§’)
        feature_count: ä½¿ç”¨ã—ãŸç‰¹å¾´é‡æ•°
    """
    p1_win_rate: float
    inference_time_ms: float
    feature_count: int


class FastStrategist:
    """
    Fast-Laneæˆ¦ç•¥ã‚¨ãƒ³ã‚¸ãƒ³
    
    LightGBMã‚’ä½¿ç”¨ã—ãŸé«˜é€Ÿå‹ç‡æ¨å®šãƒ¢ãƒ‡ãƒ«ã€‚
    Phase 1ã§ã¯åŸºæœ¬ç‰¹å¾´é‡ (HP, fainted, weather, etc.) ã®ã¿ã‚’ä½¿ç”¨ã€‚
    
    Performance Target:
    - æ¨è«–æ™‚é–“: < 10ms
    - ãƒ¡ãƒ¢ãƒª: < 10MB
    - ç²¾åº¦: 60%+ (Phase 1ç›®æ¨™)
    """
    
    def __init__(
        self,
        model: Optional[lgb.Booster] = None,
        feature_names: Optional[List[str]] = None
    ):
        """
        Args:
            model: è¨“ç·´æ¸ˆã¿LightGBMãƒ¢ãƒ‡ãƒ«
            feature_names: ç‰¹å¾´é‡åãƒªã‚¹ãƒˆ (é †åºé‡è¦)
        """
        self.model = model
        self.feature_names = feature_names or []
        
    @classmethod
    def train(
        cls,
        training_csv: Path,
        test_size: float = 0.2,
        params: Optional[Dict[str, Any]] = None
    ) -> "FastStrategist":
        """
        è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰
        
        Args:
            training_csv: ç‰¹å¾´é‡CSVãƒ•ã‚¡ã‚¤ãƒ« (extract_features.pyã®å‡ºåŠ›)
            test_size: ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®å‰²åˆ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 0.2)
            params: LightGBMãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ (Noneã®å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ)
            
        Returns:
            è¨“ç·´æ¸ˆã¿FastStrategist
        """
        print("=" * 60)
        print("ğŸš€ Fast-Lane è¨“ç·´é–‹å§‹")
        print("=" * 60)
        
        # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        print(f"\nğŸ“‚ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿: {training_csv}")
        df = pd.read_csv(training_csv)
        print(f"   - ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(df)}")
        print(f"   - P1å‹ç‡: {df['p1_win'].mean()*100:.1f}%")
        
        # ç‰¹å¾´é‡ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚’åˆ†é›¢
        feature_cols = [
            "turn",
            "rating",
            "p1_total_hp",
            "p2_total_hp",
            "hp_difference",
            "p1_fainted",
            "p2_fainted",
            "fainted_difference",
            "has_weather",
            "has_terrain",
            "has_trick_room",
            "p1_active_count",
            "p2_active_count",
        ]
        
        X = df[feature_cols]
        y = df["p1_win"]
        
        print(f"\nğŸ”§ ç‰¹å¾´é‡: {len(feature_cols)}å€‹")
        for col in feature_cols:
            print(f"   - {col}")
        
        # Train/Teståˆ†å‰²
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=test_size, random_state=42, stratify=y
        )
        
        print(f"\nğŸ“Š ãƒ‡ãƒ¼ã‚¿åˆ†å‰²:")
        print(f"   - Train: {len(X_train)}ã‚µãƒ³ãƒ—ãƒ« (P1å‹ç‡: {y_train.mean()*100:.1f}%)")
        print(f"   - Test:  {len(X_test)}ã‚µãƒ³ãƒ—ãƒ« (P1å‹ç‡: {y_test.mean()*100:.1f}%)")
        
        # LightGBM Datasetä½œæˆ
        train_data = lgb.Dataset(X_train, label=y_train)
        test_data = lgb.Dataset(X_test, label=y_test, reference=train_data)
        
        # ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        if params is None:
            params = {
                "objective": "binary",
                "metric": "binary_logloss",
                "boosting_type": "gbdt",
                "num_leaves": 31,
                "learning_rate": 0.05,
                "feature_fraction": 0.9,
                "bagging_fraction": 0.8,
                "bagging_freq": 5,
                "verbose": -1,
                "random_state": 42,
            }
        
        print(f"\nâš™ï¸  LightGBMè¨“ç·´ä¸­...")
        print(f"   - Objective: {params['objective']}")
        print(f"   - Num Leaves: {params['num_leaves']}")
        print(f"   - Learning Rate: {params['learning_rate']}")
        
        # è¨“ç·´
        model = lgb.train(
            params,
            train_data,
            num_boost_round=100,
            valid_sets=[train_data, test_data],
            valid_names=["train", "test"],
            callbacks=[
                lgb.early_stopping(stopping_rounds=10),
                lgb.log_evaluation(period=20),
            ],
        )
        
        # è©•ä¾¡
        y_pred_proba = model.predict(X_test, num_iteration=model.best_iteration)
        y_pred = (y_pred_proba > 0.5).astype(int)
        
        accuracy = (y_pred == y_test).mean()
        print(f"\nâœ… è¨“ç·´å®Œäº†")
        print(f"   - Accuracy: {accuracy*100:.1f}%")
        print(f"   - Best Iteration: {model.best_iteration}")
        
        # ç‰¹å¾´é‡é‡è¦åº¦
        importance = model.feature_importance(importance_type="gain")
        importance_df = pd.DataFrame({
            "feature": feature_cols,
            "importance": importance
        }).sort_values("importance", ascending=False)
        
        print(f"\nğŸ“Š ç‰¹å¾´é‡é‡è¦åº¦ (Top 5):")
        for _, row in importance_df.head(5).iterrows():
            print(f"   - {row['feature']}: {row['importance']:.0f}")
        
        return cls(model=model, feature_names=feature_cols)
    
    def predict(
        self,
        battle_state: BattleState
    ) -> FastPrediction:
        """
        å¯¾æˆ¦çŠ¶æ…‹ã‹ã‚‰å‹ç‡ã‚’äºˆæ¸¬
        
        Args:
            battle_state: ç¾åœ¨ã®å¯¾æˆ¦çŠ¶æ…‹
            
        Returns:
            FastPrediction (å‹ç‡ + æ¨è«–æ™‚é–“)
        """
        if self.model is None:
            raise ValueError("ãƒ¢ãƒ‡ãƒ«ãŒæœªè¨“ç·´ã§ã™ã€‚train()ã¾ãŸã¯load()ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
        
        start_time = time.perf_counter()
        
        # BattleStateã‹ã‚‰ç‰¹å¾´é‡ã‚’æŠ½å‡º
        features = self._extract_features_from_state(battle_state)
        
        # DataFrameã«å¤‰æ› (åˆ—é †åºã‚’ç¶­æŒ)
        feature_dict = {name: [features[name]] for name in self.feature_names}
        X = pd.DataFrame(feature_dict)
        
        # äºˆæ¸¬
        p1_win_rate = self.model.predict(X, num_iteration=self.model.best_iteration)[0]
        
        elapsed_ms = (time.perf_counter() - start_time) * 1000
        
        return FastPrediction(
            p1_win_rate=float(p1_win_rate),
            inference_time_ms=elapsed_ms,
            feature_count=len(self.feature_names)
        )
    
    def _extract_features_from_state(
        self,
        state: BattleState
    ) -> Dict[str, float]:
        """
        BattleStateã‹ã‚‰ç‰¹å¾´é‡ã‚’æŠ½å‡º
        
        Args:
            state: å¯¾æˆ¦çŠ¶æ…‹
            
        Returns:
            ç‰¹å¾´é‡è¾æ›¸ (feature_name -> value)
        """
        # HPåˆè¨ˆã‚’è¨ˆç®—
        p1_total_hp = sum(
            p.hp_fraction for p in state.player_a.active if p.hp_fraction > 0
        )
        p2_total_hp = sum(
            p.hp_fraction for p in state.player_b.active if p.hp_fraction > 0
        )
        
        # å€’ã‚ŒãŸãƒã‚±ãƒ¢ãƒ³æ•° (HP=0ã®ãƒã‚±ãƒ¢ãƒ³)
        p1_fainted = sum(
            1 for p in state.player_a.active if p.hp_fraction == 0
        )
        p2_fainted = sum(
            1 for p in state.player_b.active if p.hp_fraction == 0
        )
        
        # ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒã‚±ãƒ¢ãƒ³æ•°
        p1_active_count = len([p for p in state.player_a.active if p.hp_fraction > 0])
        p2_active_count = len([p for p in state.player_b.active if p.hp_fraction > 0])
        
        return {
            "turn": float(state.turn),
            "rating": 1500.0,  # Phase 1ã§ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
            "p1_total_hp": p1_total_hp,
            "p2_total_hp": p2_total_hp,
            "hp_difference": (p1_total_hp - p2_total_hp) / 2.0,
            "p1_fainted": float(p1_fainted),
            "p2_fainted": float(p2_fainted),
            "fainted_difference": float(p2_fainted - p1_fainted),
            "has_weather": 1.0 if state.weather else 0.0,
            "has_terrain": 1.0 if state.terrain else 0.0,
            "has_trick_room": 0.0,  # Phase 1ã§ã¯æœªå®Ÿè£…
            "p1_active_count": float(p1_active_count),
            "p2_active_count": float(p2_active_count),
        }
    
    def save(self, filepath: Path):
        """
        ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜
        
        Args:
            filepath: ä¿å­˜å…ˆãƒ‘ã‚¹ (.pkl)
        """
        if self.model is None:
            raise ValueError("ãƒ¢ãƒ‡ãƒ«ãŒæœªè¨“ç·´ã§ã™")
        
        filepath.parent.mkdir(parents=True, exist_ok=True)
        
        with open(filepath, "wb") as f:
            pickle.dump({
                "model": self.model,
                "feature_names": self.feature_names,
            }, f)
        
        print(f"ğŸ’¾ ãƒ¢ãƒ‡ãƒ«ä¿å­˜: {filepath}")
        print(f"   ã‚µã‚¤ã‚º: {filepath.stat().st_size / 1024:.1f} KB")
    
    @classmethod
    def load(cls, filepath: Path) -> "FastStrategist":
        """
        ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿
        
        Args:
            filepath: ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ (.pkl)
            
        Returns:
            FastStrategist
        """
        with open(filepath, "rb") as f:
            data = pickle.load(f)
        
        print(f"ğŸ“‚ ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿: {filepath}")
        print(f"   ç‰¹å¾´é‡æ•°: {len(data['feature_names'])}")
        
        return cls(
            model=data["model"],
            feature_names=data["feature_names"]
        )
